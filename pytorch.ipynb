{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoBCGF/f3+uzaniWnlnH/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushal2022/Pytorch/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic PyTorch"
      ],
      "metadata": {
        "id": "1Pf1ejwhu_97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "weights = torch.tensor([0.2126, 0.7152, 0.0722], requires_grad=True)\n",
        "\n",
        "for epoch in range(10):\n",
        "  model_output = (weights * 3).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh2XfwatvDFK",
        "outputId": "2b2bd291-8496-41f3-b2d4-2ff416676de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "source": [
        "weights = torch.tensor([0.2126, 0.7152, 0.0722], requires_grad=True)\n",
        "\n",
        "# Wrap the weights tensor in a list to make it an iterable\n",
        "optimizer = torch.optim.SGD([weights], lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  model_output = (weights * 3).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LayKPUUowYCf",
        "outputId": "f5aa45cf-3741-405c-df7d-d6dacdc7ee9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n",
            "tensor([3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Back propagation example with pytorch**"
      ],
      "metadata": {
        "id": "-ZPaZbKD0mri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "### update weights\n",
        "### next forward and backward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGBg1bCD0zKC",
        "outputId": "d45e115b-38db-4ef2-adb3-ea1ded31c3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Prediction : Pytorch Model\n",
        "* Gradients Computation : Autograd\n",
        "* Loss Computation : Pytorch Loss\n",
        "* Parameter Updates : Pytorch Optimizer"
      ],
      "metadata": {
        "id": "2Pr-gwpqtyRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Linear function\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# Model Prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# Loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y)**2).mean()\n",
        "\n",
        "# Gradient\n",
        "# MSE = 1/N * (w * x - y)**2\n",
        "# dJ/dw = 1/N 2*(w * x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "  return np.dot(2*x, y_pred - y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "\n",
        "  # update wieghts\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "379banWRuFt0",
        "outputId": "73d0c9ba-0769-45fc-c53f-0c16be52b09a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 1.200, loss = 30.00000000\n",
            "epoch 3: w = 1.872, loss = 0.76800019\n",
            "epoch 5: w = 1.980, loss = 0.01966083\n",
            "epoch 7: w = 1.997, loss = 0.00050332\n",
            "epoch 9: w = 1.999, loss = 0.00001288\n",
            "epoch 11: w = 2.000, loss = 0.00000033\n",
            "epoch 13: w = 2.000, loss = 0.00000001\n",
            "epoch 15: w = 2.000, loss = 0.00000000\n",
            "epoch 17: w = 2.000, loss = 0.00000000\n",
            "epoch 19: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Linear function\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# Model Prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# Loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update wieghts\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  # zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFpdDSKbwXVr",
        "outputId": "d1903862-ca92-45ad-a84b-fc79e2c0e841"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 3: w = 0.772, loss = 15.66018772\n",
            "epoch 5: w = 1.113, loss = 8.17471695\n",
            "epoch 7: w = 1.359, loss = 4.26725292\n",
            "epoch 9: w = 1.537, loss = 2.22753215\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 13: w = 1.758, loss = 0.60698116\n",
            "epoch 15: w = 1.825, loss = 0.31684780\n",
            "epoch 17: w = 1.874, loss = 0.16539653\n",
            "epoch 19: w = 1.909, loss = 0.08633806\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 23: w = 1.952, loss = 0.02352631\n",
            "epoch 25: w = 1.966, loss = 0.01228084\n",
            "epoch 27: w = 1.975, loss = 0.00641066\n",
            "epoch 29: w = 1.982, loss = 0.00334642\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 33: w = 1.991, loss = 0.00091188\n",
            "epoch 35: w = 1.993, loss = 0.00047601\n",
            "epoch 37: w = 1.995, loss = 0.00024848\n",
            "epoch 39: w = 1.996, loss = 0.00012971\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 43: w = 1.998, loss = 0.00003534\n",
            "epoch 45: w = 1.999, loss = 0.00001845\n",
            "epoch 47: w = 1.999, loss = 0.00000963\n",
            "epoch 49: w = 1.999, loss = 0.00000503\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 53: w = 2.000, loss = 0.00000137\n",
            "epoch 55: w = 2.000, loss = 0.00000071\n",
            "epoch 57: w = 2.000, loss = 0.00000037\n",
            "epoch 59: w = 2.000, loss = 0.00000019\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 63: w = 2.000, loss = 0.00000005\n",
            "epoch 65: w = 2.000, loss = 0.00000003\n",
            "epoch 67: w = 2.000, loss = 0.00000001\n",
            "epoch 69: w = 2.000, loss = 0.00000001\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 73: w = 2.000, loss = 0.00000000\n",
            "epoch 75: w = 2.000, loss = 0.00000000\n",
            "epoch 77: w = 2.000, loss = 0.00000000\n",
            "epoch 79: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 83: w = 2.000, loss = 0.00000000\n",
            "epoch 85: w = 2.000, loss = 0.00000000\n",
            "epoch 87: w = 2.000, loss = 0.00000000\n",
            "epoch 89: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "epoch 93: w = 2.000, loss = 0.00000000\n",
            "epoch 95: w = 2.000, loss = 0.00000000\n",
            "epoch 97: w = 2.000, loss = 0.00000000\n",
            "epoch 99: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Design model (input size, output size, forward pass)\n",
        "2. Construct the loss and optimizer\n",
        "3. Training loop\n",
        "  - forward pass : compute prediction\n",
        "  - backward pass : gradients\n",
        "  - update the weights"
      ],
      "metadata": {
        "id": "2IOWBTSmAkuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear function\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "#model = nn.Linear(1, 1)\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 1000\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update wieghts\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "pNo6mmWW_0P1",
        "outputId": "91374ea7-f89f-4a3b-b6a1-92921dab6a50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d54ea5a7f55f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regressing using pytorch inbuild library**"
      ],
      "metadata": {
        "id": "l8nrLzi63gV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Num\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "\n",
        "#model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "#loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #updates\n",
        "  optimizer.step()\n",
        "\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if((epoch+1) % 10 == 0):\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "#plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "LMUUGVmLBnXh",
        "outputId": "62c2ba2d-4c93-49ca-b9e1-f21f5eab0103"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4294.2295\n",
            "epoch: 20, loss = 3204.2532\n",
            "epoch: 30, loss = 2416.1035\n",
            "epoch: 40, loss = 1845.5670\n",
            "epoch: 50, loss = 1432.1323\n",
            "epoch: 60, loss = 1132.2546\n",
            "epoch: 70, loss = 914.5510\n",
            "epoch: 80, loss = 756.3747\n",
            "epoch: 90, loss = 641.3632\n",
            "epoch: 100, loss = 557.6791\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression using Pytorch**"
      ],
      "metadata": {
        "id": "VWAS8ggN3pZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* preparing the data\n",
        "* model\n",
        "* loss and optimizer\n",
        "* Traning loop"
      ],
      "metadata": {
        "id": "0ucoxMN33_4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "#print(n_samples, n_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "#scale the feature\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "#model\n",
        "#f = wx + b, and apply sigmoid at the end\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "#Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#traning loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X_train)\n",
        "\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #updates\n",
        "  optimizer.step()\n",
        "\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if((epoch+1) % 10 == 0):\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc:.4f}')"
      ],
      "metadata": {
        "id": "ohHiKq9b3-a-",
        "outputId": "e9a556a9-9683-484f-d364-bd55a0fd780d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5349\n",
            "epoch: 20, loss = 0.4453\n",
            "epoch: 30, loss = 0.3872\n",
            "epoch: 40, loss = 0.3466\n",
            "epoch: 50, loss = 0.3165\n",
            "epoch: 60, loss = 0.2932\n",
            "epoch: 70, loss = 0.2746\n",
            "epoch: 80, loss = 0.2593\n",
            "epoch: 90, loss = 0.2464\n",
            "epoch: 100, loss = 0.2354\n",
            "accuracy = 0.9035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t_6Fomkk4oi8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}